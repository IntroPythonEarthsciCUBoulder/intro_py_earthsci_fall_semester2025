{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA ANALYSIS USING PYTHON PANDAS LIBRARY\n",
    "\n",
    "Oct 2023 <br>\n",
    "By Irina Overeem\n",
    "\n",
    "We will be looking at data on river discharge of the Upper Colorado River. \n",
    "Tabular data like this with a combination of dates, name and data quality strings, and numbers are best handled by spreadsheets where entries such as dates and times are in some useful format. In Python the Python Data Analysis Library (a.k.a. Pandas) is really useful for this purpose.\n",
    "\n",
    "I use one discharge data file downloaded for the USGS station at Kremmling, CO, for the Upper Colorado. \n",
    "And we will look at a file generated by a commonly used electronic setup - a campbell scientific datalogger.\n",
    "\n",
    "In this notebook will use partially cleaned up files, because the headers in either the USGS files and to some extent also the Campbell stations is unique for each station, making it difficult to deal with it in an automated way. To prepare the file I cut of the header in a text-editor, cut the line that has 15 s ..., and saved it as a *.csv file. \n",
    "\n",
    "Python Learning Objectives:\n",
    "1. Load csv data from a file using the Pandas library.\n",
    "2. Get info on the data in a dataframe, access data in DataFrames.\n",
    "3. Create plots of data in DataFrames.\n",
    "4. Save figures to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up with the modules we will use\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOME REVIEW NOTES FROM LAST WEEK\n",
    "\n",
    "### Reading file data into a numpy array: loadtxt and genfromtxt\n",
    "\n",
    "If our goal is to read the contents of a text file into a numpy array, numpy provides functions that makes this a bit easier:\n",
    "\n",
    "`loadtxt()` - simple and effective when you have all numbers plus some comments or header lines <br>\n",
    "`genfromtxt()` - useful when there are strings embedded in the data portion of the file <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(np.loadtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Example of loadtxt on glacial data\n",
    "#Our file has 2 header lines that we need to skip; we use the skiprows parameter\n",
    "#It is comma-separated; we use the delimiter parameter\n",
    "\n",
    "har = np.loadtxt(\"hardangerjokulen2006-2007.csv\", skiprows=2, delimiter=\",\")\n",
    "print(har)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the Pandas Module?\n",
    "\n",
    "The Python module **Pandas** is designed to efficiently work with tabular data.\n",
    "\n",
    "DataFrame: a two-dimensional data structure that holds data like a two-dimension array or a table with rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load a csv-file into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data file posted with this excercise into a pandas dataframe\n",
    "\n",
    "data = pd.read_csv('USGS09058000_discharge_NoHead_20112021.csv')\n",
    "\n",
    "# print the first five lines to see whether it populated the fields\n",
    "# with the head() method, you can see the structure of the data without having to print the entire dataframe.\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just created a Data Frame.<br>\n",
    "\n",
    "A DataFrame is a 2-dimensional data structure that can store data of different types (including characters, integers, floating point values, factors and more) in columns. It is similar to a spreadsheet, or an database/ SQL table.\n",
    "\n",
    "To get quick insight in what is in a dataframe, you can use the head() method or the tail() method.\n",
    "\n",
    "You can check the type of the object data using the type module. The type() method or the  __class__ attribute tell us what type of object the variable points to.\n",
    "\n",
    "Then: each column in a DataFrame also has its own type. We can use data.dtypes to view the data type for each column. int64 are numeric integer values, object are strings (letters and numbers), and float64 are numbers with decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get insight in the content of a dataframe, you can use the head() method or the tail() method:\n",
    "data.head()\n",
    "#data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the type() function works too\n",
    "\n",
    "print(type(data))\n",
    "print(data.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a list with new column names as strings\n",
    "new_column_names = ['Agency', 'SiteNo', 'OldDateTime', 'Discharge_cfs']\n",
    "\n",
    "# assign the new column names to the dataframe\n",
    "data.columns = new_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in each column of a Pandas DataFrame can be accessed using the specific column name. <br>\n",
    "If we want to access more than one column at once, we use a list of column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, if we just want to select the discharge in cu ft/sec\n",
    "data[['Discharge_cfs']].head()\n",
    "\n",
    "# or as a second example, we just want to select time and discharge\n",
    "data[['OldDateTime','Discharge_cfs']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating data in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations\n",
    "# We can also call the data using column names and manipulate the values in the column\n",
    "# For example, here we convert the discharge from cubic feet per second to metric units m3/sec \n",
    "\n",
    "data['Discharge_m3sec'] = data['Discharge_cfs'] * 0.028316847 \n",
    "data['Discharge_m3sec'].head()\n",
    "\n",
    "len(data['Discharge_m3sec'])\n",
    "\n",
    "data.head()\n",
    "\n",
    "# So we added a column with the newly calculated parameter.\n",
    "\n",
    "#INSTEAD You can also replace the existing values in Discharge_cfs column by setting the column name equal to the output of the applied function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When Pandas imported the data, it read the station name (a number) as an integer and removed the initial zero. We can fix the station name by replacing the values of that column with a string.\n",
    "Remember that the goal is to automate the process for multiple stations. Instead of writing the corrected station name ourselves, let’s build it from the values available in the DataFrame.\n",
    "\n",
    "The Pandas method unique returns a numpy array of the unique elements in the DataFrame. We want the first (and only) entry in that array, which has the index 0. We can build a string with the correct station name by casting that value as a string and concatenating it with an initial zero.\n",
    "\n",
    "We can replace all values in the ‘Station’ column with this string through assignment and check the object type of each column to make sure it is no longer an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulation of strings in one of the columns of the dataframe\n",
    "\n",
    "new_station_name = \"0\" + str(data['SiteNo'].unique()[0])\n",
    "data['SiteNo'] = new_station_name\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max, min and basic stats can be easily found with a couple of math methods built into pandas\n",
    "\n",
    "print(data['Discharge_m3sec'].max())\n",
    "print(data['Discharge_m3sec'].min())\n",
    "\n",
    "print(data['Discharge_m3sec'].mean())\n",
    "print(data['Discharge_m3sec'].std())\n",
    "\n",
    "# also very handy for inquiries is to find the index of these max values\n",
    "peakflowindex=data['Discharge_m3sec'].idxmax()\n",
    "\n",
    "print(peakflowindex)\n",
    "\n",
    "peakflowday=data['DateTime'][peakflowindex]\n",
    "print(peakflowday)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Date and Time stamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different programming languages and software packages handle date and time stamps in their own unique ways. Pandas has a set of functions for creating and managing timeseries.\n",
    "\n",
    "We need to convert the USGS entries in the DateTime column into a format that Pandas can work with. Luckily, the to_datetime function in the Pandas library can convert it directly. Note that this conversion takes up a bit of time, wait till you see those first five lines reported....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the pd.to_datetime functionality\n",
    "\n",
    "data['DateTime'] = pd.to_datetime(data['OldDateTime'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The entries in our DataFrame data are indexed by the number in bold on the left side of each row. \n",
    "# We can display a slice of the data using index ranges:\n",
    "\n",
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <font color = green> IN-CLASS PRACTICE </font> \n",
    "\n",
    "Can you print out the river discharge on 1/10/11?\n",
    "Can you print out the very last entry in the dataset? When was this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your print statements here\n",
    "\n",
    "data[\"Discharge_m3sec\"][9]\n",
    "\n",
    "#last=(len(data))-1\n",
    "\n",
    "#print(data[\"Discharge_m3sec\"][last])\n",
    "#print(data[\"DateTime\"][last])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data subsets and removing columns\n",
    "\n",
    "We can select specific ranges of our data in both the row and column directions using either label or integer-based indexing.\n",
    "\n",
    "loc: indexing via labels or integers <br>\n",
    "iloc: indexing via integers <br>\n",
    "\n",
    "To select a subset of rows AND columns from our DataFrame, we can use the loc method and the integer indices for both rows and columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[0:2, ['DateTime', 'Discharge_m3sec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0:2,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('With iloc:', data.iloc[0:2,-2:].shape)\n",
    "print('With loc:', data.loc[0:2, ['DateTime', 'Discharge_m3sec']].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can call individual columns (or lists of columns) from a DataFrame, the simplest way to remove columns is by creating a new DataFrame with only the columns we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_data = data[['DateTime', 'Discharge_m3sec']]\n",
    "discharge_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is possible to separate components of the date time\n",
    "# here we use dt.year to just select the year in a separate column\n",
    "data['year'] = data['DateTime'].dt.year\n",
    "data.head()\n",
    "\n",
    "\n",
    "#Q2011=  data[data.year == 2011]\n",
    "#print(Q2011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <font color = green> IN CLASS PRACTICE </font> \n",
    "\n",
    "First, use the iloc method to create a new dataframe that has DateTime and Discharge over just 2020. \n",
    "To check whether you have selected indeed the whole year, print out the last 12 values of the newly created data frame.\n",
    "\n",
    "Then use the dt.year functionality to create a new dataframe that has DateTime and Discharge over just 2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here using iloc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code using the dt.year functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Plots of Pandas Dataframes\n",
    "\n",
    "Pandas is well integrated with the matplotlib library that we used earlier in the tutorials. \n",
    "We can either use the same functions we used before with to plot data in NumPy arrays or we can use the plotting functions built into Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters \n",
    "register_matplotlib_converters()\n",
    "\n",
    "plt.plot(data['DateTime'], data['Discharge_cfs'])\n",
    "plt.title('Gauging Station ' + data['SiteNo'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(x='DateTime', y='Discharge_cfs', title='Station ' + data['SiteNo'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(x='DateTime', y='Discharge_cfs', title='Station ' + data['SiteNo'][0])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Discharge (cfs)')\n",
    "\n",
    "# to save your figure to a file, specify a name before the final plotting command\n",
    "plt.savefig('USGStestplot.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <font color = green> IN-CLASS PRACTICE </font> \n",
    "\n",
    "1. make a plot of discharge over 2019 only\n",
    "2. relabel the title to call this USGS station at Kremmling, CO\n",
    "3. plot the line in black\n",
    "4. save your figure to a png file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logical Operators with DataFrames to Filter Values\n",
    "\n",
    "Another useful data wrangling option is the ability to filter data from an existing pandas dataframe.\n",
    "\n",
    "Filtering data is easily done using dataframe.column_name == \"value\". Your output will contain all rows that meet the criteria.\n",
    "\n",
    "For example, you can filter using a comparison operator on numeric values. For example, you can select all rows from the dataframe that have discharge greater than 8500 cfs by filtering on the Discharge_in_cfs column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe from filter on values in the `Discharge_cfs` column greater than 8500 cfs\n",
    "\n",
    "High_discharge_days = data[data.Discharge_cfs > 8500]\n",
    "\n",
    "# print new dataframe\n",
    "High_discharge_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <font color = green> IN-CLASS PRACTICE </font> \n",
    " \n",
    "1. what is the lowest flow recorded at the Kremmling USGS station?\n",
    "2. Use the `nsmallest` method to create new dataframe from filter on values in the `Discharge_cfs` column that captures the 10 lowest flow days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "data.Discharge_cfs.min()\n",
    "\n",
    "low_flow = data.nsmallest(1, \"Discharge_cfs\")\n",
    "print(\"The lowest flow recorded,\", low_flow[\"Discharge_cfs\"].item(), \"cfs, occurred on\", low_flow[\"DateTime\"].item())\n",
    "\n",
    "data.nsmallest(10, \"Discharge_cfs\")\n",
    "#print(\"The tenth lowest flow is 308.8 cfs\")\n",
    "\n",
    "ten_lowest = data[data.Discharge_cfs < 309]\n",
    "print(ten_lowest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
